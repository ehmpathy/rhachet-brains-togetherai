# blackbox criteria: rhachet-brains-togetherai

> experience boundaries â€” what users see, do, and receive

---

# usecase.1 = generate brain atom

```
given('a valid together-ai atom slug')
  when('genBrainAtom is called with the slug')
    then('a BrainAtom instance is returned')
      sothat('users can invoke .ask() on it')
    then('the atom has the correct spec (cost, context, grades)')
      sothat('users can inspect capabilities before use')
    then('the atom has a description that identifies the model')
      sothat('users can log/display which brain is active')

given('an invalid slug that does not match any model')
  when('genBrainAtom is called')
    then('a type error is raised at compile time')
      sothat('users cannot accidentally use unsupported models')
```

---

# usecase.2 = ask brain for structured output

```
given('a brain atom instance')
  when('ask is called with a prompt and zod schema')
    then('the response contains output that matches the schema')
      sothat('users get type-safe structured data')
    then('the response contains metrics with token counts')
      sothat('users can track usage')
    then('the response contains metrics with cost breakdown')
      sothat('users can track spend per call')
    then('the response contains an episode for continuation')
      sothat('users can build multi-turn conversations')

given('a brain atom instance')
  when('ask is called with role.briefs populated')
    then('the briefs are included as system context')
      sothat('users can inject domain knowledge')

given('a brain atom instance')
  when('ask is called with an empty prompt')
    then('the call still succeeds with model response')
      sothat('edge cases are handled gracefully')
```

---

# usecase.3 = track cost and metrics

```
given('a completed brain.ask call')
  when('metrics are inspected')
    then('metrics.cost.cash.input reflects input token cost')
    then('metrics.cost.cash.output reflects output token cost')
    then('metrics.cost.cash.total reflects combined cost')
    then('metrics.cost.time.milliseconds reflects elapsed duration')
    then('metrics.size.tokens.input reflects prompt tokens')
    then('metrics.size.tokens.output reflects completion tokens')
    then('metrics.size.tokens.cache.get reflects cached tokens (if any)')
      sothat('users have full visibility into resource consumption')

given('a model with known swe-bench score')
  when('the brain spec is inspected')
    then('spec.gain.grades.swe contains the benchmark score')
      sothat('users can compare model capabilities')
```

---

# usecase.4 = continue conversation (episode)

```
given('a prior brain.ask response with episode')
  when('ask is called again with on.episode set to prior episode')
    then('the prior exchanges are included in context')
      sothat('the model has conversation history')
    then('the new response extends the episode')
      sothat('multi-turn flows can be built')

given('no prior episode')
  when('ask is called without on.episode')
    then('a fresh episode is started')
      sothat('single-turn usage works without extra config')
```

---

# usecase.5 = handle errors gracefully

```
given('TOGETHER_API_KEY is not set in environment')
  when('brain.ask is called')
    then('an error is thrown with clear message about absent api key')
      sothat('users know exactly what to configure')

given('the together-ai api returns an error')
  when('brain.ask is called')
    then('the error is propagated with context')
      sothat('users can diagnose api issues')

given('the model returns malformed json')
  when('brain.ask parses the response')
    then('a parse error is thrown with the raw content')
      sothat('users can debug schema mismatches')

given('the zod schema does not match the response shape')
  when('brain.ask validates output')
    then('a validation error is thrown with schema details')
      sothat('users can fix their schema definitions')
```

---

# usecase.6 = drop-in replacement for xai

```
given('code that uses rhachet-brains-xai')
  when('the import is changed to rhachet-brains-togetherai')
    then('the same genBrainAtom function is available')
    then('the same BrainAtom type is returned')
    then('the same .ask() contract is supported')
    then('the same metrics shape is returned')
      sothat('migration requires only import + slug change')

given('a together-ai slug like "together/qwen3/coder-next"')
  when('compared to xai slug pattern "xai/grok/code-fast-1"')
    then('both follow the same {repo}/{family}/{model} convention')
      sothat('users have consistent mental model across adapters')
```

---

# usecase.7 = access model specs

```
given('a brain atom for qwen3-coder-next')
  when('spec is inspected')
    then('spec.cost.cash.input equals $0.07 per 1M tokens')
    then('spec.cost.cash.output equals $0.30 per 1M tokens')
    then('spec.gain.size.context.tokens equals 262000')
    then('spec.gain.grades.swe equals 70.6')
      sothat('users can make informed model choices')

given('a brain atom for deepseek-v3.2')
  when('spec is inspected')
    then('spec.cost.cash.input equals $0.28 per 1M tokens')
    then('spec.cost.cash.output equals $0.42 per 1M tokens')
    then('spec.gain.size.context.tokens equals 128000')
    then('spec.gain.grades.swe equals 73.0')
      sothat('users can compare cost/performance tradeoffs')
```

---

# usecase.8 = sdk exports

```
given('the package is installed')
  when('the user imports from "rhachet-brains-togetherai"')
    then('genBrainAtom is exported')
    then('TogetherBrainAtomSlug type is exported')
      sothat('users can type their slug variables')
    then('CONFIG_BY_ATOM_SLUG is exported')
      sothat('advanced users can inspect all model configs')
```
